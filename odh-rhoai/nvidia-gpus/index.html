<!-- Elements added to main will be displayed on all pages -->

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift.">
      
      
      
        <link rel="canonical" href="https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/">
      
      
        <link rel="prev" href="../model-serving-type-modification/">
      
      
        <link rel="next" href="../openshift-group-management/">
      
      
      <link rel="icon" href="../../assets/robot-head.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.50">
    
    
      
        <title>NVIDIA GPUs - AI on OpenShift</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EXFP0W7LTY"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EXFP0W7LTY",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EXFP0W7LTY",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="NVIDIA GPUs - AI on OpenShift" >
      
        <meta  property="og:description"  content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift." >
      
        <meta  property="og:image"  content="https://ai-on-openshift.io/assets/images/social/odh-rhoai/nvidia-gpus.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="NVIDIA GPUs - AI on OpenShift" >
      
        <meta  name="twitter:description"  content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift." >
      
        <meta  name="twitter:image"  content="https://ai-on-openshift.io/assets/images/social/odh-rhoai/nvidia-gpus.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#working-with-gpus" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="AI on OpenShift" class="md-header__button md-logo" aria-label="AI on OpenShift" data-md-component="logo">
      
  <img src="../../assets/robot-head.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI on OpenShift
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              NVIDIA GPUs
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="red"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/opendatahub-io-contrib/ai-on-openshift" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../whats-new/whats-new/" class="md-tabs__link">
          
  
    
  
  Overview

        </a>
      </li>
    
  

    
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../from-zero-to-workbench/using-cli/" class="md-tabs__link">
          
  
    
  
  ODH/RHOAI How-Tos

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../tools-and-applications/ensemble-serving/ensemble-serving/" class="md-tabs__link">
          
  
    
  
  Applications and Patterns

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../predictive-ai/what-is-predictive-ai/" class="md-tabs__link">
          
  
    
  
  Predictive AI

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../generative-ai/what-is-generative-ai/" class="md-tabs__link">
          
  
    
  
  Generative AI

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="AI on OpenShift" class="md-nav__button md-logo" aria-label="AI on OpenShift" data-md-component="logo">
      
  <img src="../../assets/robot-head.svg" alt="logo">

    </a>
    AI on OpenShift
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/opendatahub-io-contrib/ai-on-openshift" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Overview
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Overview
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    What's new?
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            What's new?
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../whats-new/whats-new/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latest updates
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/why-this-site/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Why this site?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/openshift/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift and AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/opendatahub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open Data Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/openshift-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift AI
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    ODH/RHOAI How-Tos
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            ODH/RHOAI How-Tos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    From Zero to Workbench
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            From Zero to Workbench
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../from-zero-to-workbench/using-cli/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the CLI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../from-zero-to-workbench/using-ui/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the UI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../from-zero-to-workbench/using-developer-hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Developer Hub
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Advanced Configuration
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Advanced Configuration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerator-profiles/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerator Profiles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../custom-notebooks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom notebooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../custom-runtime-triton/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Serving Runtime (Triton)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../configuration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dashboard configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-models-from-public-oci/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying Models from Public OCI Registries
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gitops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitOps (CRs, objects,...)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../secret-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Managing Secrets in an AI Platform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kueue-preemption/readme/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kueue preemption
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model-serving-type-modification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model serving type modification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    NVIDIA GPUs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    NVIDIA GPUs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#using-nvidia-gpus-on-openshift" class="md-nav__link">
    <span class="md-ellipsis">
      Using NVIDIA GPUs on OpenShift
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Using NVIDIA GPUs on OpenShift">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-does-this-work" class="md-nav__link">
    <span class="md-ellipsis">
      How does this work?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#working-with-taints" class="md-nav__link">
    <span class="md-ellipsis">
      Working with taints
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoscaler-and-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      Autoscaler and GPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Autoscaler and GPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaling-to-zero" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling to zero
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-partitioning-sharing" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Partitioning / Sharing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPU Partitioning / Sharing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-slicing-gpu-sharing" class="md-nav__link">
    <span class="md-ellipsis">
      Time Slicing (GPU sharing)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Time Slicing (GPU sharing)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration_1" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-instance-gpu-mig" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Instance GPU (MIG)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-process-service-mps" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Process Service (MPS)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregating-gpus-multi-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Aggregating GPUs (Multi-GPU)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvidia-vgpus" class="md-nav__link">
    <span class="md-ellipsis">
      NVIDIA vGPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVIDIA vGPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pros" class="md-nav__link">
    <span class="md-ellipsis">
      Pros
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons" class="md-nav__link">
    <span class="md-ellipsis">
      Cons
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgpu-drivers" class="md-nav__link">
    <span class="md-ellipsis">
      vGPU Drivers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#licensing" class="md-nav__link">
    <span class="md-ellipsis">
      Licensing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openshift-group-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift Group Management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../single-stack-serving-certificate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single stack serving certificate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kserve-timeout/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KServe Timeout Issues
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kserve-uwm-dashboard-metrics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RHOAI Metrics Dashboard for Model Serving
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../connect-vscode-to-rhoai-wb/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Connect to RHOAI Workbench Kernel from VS Code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../custom-workbench-anythingllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AnythingLLM as Custom Workbench
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-validated-models-on-disconnected/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying a Red Hat Validated Model in a Disconnected OpenShift AI Environment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    GitOps
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            GitOps
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gitops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitOps (CRs, objects,...)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rhoaibu-cluster-gitops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RHOAI BU Cluster GitOps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../secret-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Managing Secrets in an AI Platform
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tools
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpu-pruner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPU pruner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../odh-tools-and-extensions-companion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ODH Tools and Extensions Companion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../image-puller/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Kubernetes Image Puller Operator to Speed Up Start-Up Times
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../enable-function-calling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Function / Tool Calling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm-guardrails/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM GuardRails
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion_safety_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion Safety Checker
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Applications and Patterns
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Applications and Patterns
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Serving
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Model Serving
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/ensemble-serving/ensemble-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ensemble Serving
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data processing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Data processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/apache-nifi/apache-nifi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache NiFi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/apache-spark/apache-spark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Spark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/riva/riva/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NVIDIA Riva
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/starproxy/starproxy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Starburst/Trino proxy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Workflows
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            Workflows
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/airflow/airflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Airflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/mlflow/mlflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MLflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/datasciencepipeline/datasciencepipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Science Pipeline
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Storage
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            Storage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/minio/minio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Minio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools-and-applications/rclone/rclone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rclone
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Architecture Patterns
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            Architecture Patterns
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/bucket-notifications/bucket-notifications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bucket notifications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/kafka/kafka-to-object-storage/kafka-to-object-storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kafka to object storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/kafka/kafka-to-serverless/kafka-to-serverless/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kafka to serverless
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Predictive AI
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Predictive AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../predictive-ai/what-is-predictive-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Predictive AI?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Demos
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Demos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/credit-card-fraud-detection-mlflow/credit-card-fraud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Credit Card Fraud Detection with MLFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/financial-fraud-detection/financial-fraud-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Financial Fraud Detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/retail-object-detection/retail-object-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Object Detection in Retail
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/smart-city/smart-city/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Smart City
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/telecom-customer-churn-airflow/telecom-customer-churn-airflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Telecom Customer Churn with Airflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/water-pump-failure-prediction/water-pump-failure-prediction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Water Pump Failure Prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/xray-pipeline/xray-pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XRay Pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/yolov5-training-serving/yolov5-training-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLOv5 Training and Serving
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Generative AI
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Generative AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generative-ai/what-is-generative-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Generative AI?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generative-ai/llm-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM Serving
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generative-ai/building-an-image-generation-app/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building an Image Generation App
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Demos
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            Demos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generative-ai/ai-for-everyone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI for Everyone
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/llm-chat-doc/llm-chat-doc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chat with your documentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/codellama-continue/codellama-continue/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code assistant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/llama2-finetune/llama2-finetune/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning Llama2 with Ray
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/llama3-finetune/llama3-finetune-kfto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tune Llama3 with KFTO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/podman-ai-lab-to-rhoai/podman-ai-lab-to-rhoai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From Podman AI Lab to OpenShift AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/stable-diffusion/stable-diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text to Image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../demos/modelops-benchmarking/modelops-benchmarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Secure Model Ingestion and Evaluation with OpenShift AI
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#using-nvidia-gpus-on-openshift" class="md-nav__link">
    <span class="md-ellipsis">
      Using NVIDIA GPUs on OpenShift
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Using NVIDIA GPUs on OpenShift">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-does-this-work" class="md-nav__link">
    <span class="md-ellipsis">
      How does this work?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#working-with-taints" class="md-nav__link">
    <span class="md-ellipsis">
      Working with taints
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoscaler-and-gpus" class="md-nav__link">
    <span class="md-ellipsis">
      Autoscaler and GPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Autoscaler and GPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaling-to-zero" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling to zero
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-partitioning-sharing" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Partitioning / Sharing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPU Partitioning / Sharing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-slicing-gpu-sharing" class="md-nav__link">
    <span class="md-ellipsis">
      Time Slicing (GPU sharing)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Time Slicing (GPU sharing)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration_1" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-instance-gpu-mig" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Instance GPU (MIG)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-process-service-mps" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Process Service (MPS)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregating-gpus-multi-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Aggregating GPUs (Multi-GPU)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvidia-vgpus" class="md-nav__link">
    <span class="md-ellipsis">
      NVIDIA vGPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVIDIA vGPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pros" class="md-nav__link">
    <span class="md-ellipsis">
      Pros
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons" class="md-nav__link">
    <span class="md-ellipsis">
      Cons
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgpu-drivers" class="md-nav__link">
    <span class="md-ellipsis">
      vGPU Drivers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#licensing" class="md-nav__link">
    <span class="md-ellipsis">
      Licensing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="working-with-gpus">Working with GPUs</h1>
<h2 id="using-nvidia-gpus-on-openshift">Using NVIDIA GPUs on OpenShift</h2>
<h3 id="how-does-this-work">How does this work?</h3>
<p>NVIDIA GPUs can be easily installed on OpenShift. Basically it involves installing two different operators.</p>
<p>The Node Feature Discovery operator will "discover" your cards from a hardware perspective and appropriately label the relevant nodes with this information.</p>
<p>Then the NVIDIA GPU operator will install the necessary drivers and tooling to those nodes. It will also integrate into Kubernetes so that when a Pod requires GPU resources it will be scheduled on the right node, and make sure that the containers are "injected" with the right drivers,  configurations and tools to properly use the GPU.</p>
<p>So from a user perspective, the only thing you have to worry about is asking for GPU resources when defining your pods, with something like:</p>
<div class="highlight"><pre><span></span><code><span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">app</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">        </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;64Mi&quot;</span>
<span class="w">        </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;250m&quot;</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">        </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;128Mi&quot;</span>
<span class="w">        </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;500m&quot;</span>
</code></pre></div>
<p>But don't worry, OpenShift AI and Open Data Hub take care of this part for you when you launch notebooks, workbenches, model servers, or pipeline runtimes!</p>
<h3 id="installation">Installation</h3>
<p>Here is the documentation you can follow:</p>
<ul>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_science_self-managed/1-latest/html/installing_openshift_data_science_self-managed/enabling-gpu-support-in-openshift-data-science_install">OpenShift AI documentation</a></li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html">NVIDIA documentation (more detailed)</a></li>
</ul>
<h2 id="advanced-configuration">Advanced configuration</h2>
<h3 id="working-with-taints">Working with taints</h3>
<p>In many cases, you will want to restrict access to GPUs, or be able to provide choice between different types of GPUs: simply stating "I want a GPU" is not enough. Also, if you want to make sure that <strong>only the Pods requiring GPUs</strong> end up on GPU-enabled nodes (and not other Pods that just end up being there at random because that's how Kubernetes works...), you're at the right place!</p>
<p>The only supported method at the moment to achieve this is to taint nodes, then apply tolerations on the Pods depending on where you want them scheduled. If you don't pay close attention though when applying taints on Nodes, you may end up with the NVIDIA drivers not installed on those nodes...</p>
<p>In this case you must:</p>
<ul>
<li>
<p>Apply the taints you need to your Nodes or MachineSets, for example:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">selector</span><span class="p">:</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">template</span><span class="p">:</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">spec</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">taints</span><span class="p p-Indicator">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">restrictedaccess</span>
<span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;yes&quot;</span>
<span class="w">          </span><span class="nt">effect</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">NoSchedule</span>
</code></pre></div>
</li>
<li>
<p>Apply the relevant toleration to the NVIDIA Operator.</p>
<ul>
<li>
<p>In the <code>nvidia-gpu-operator</code> namespace, get to the Installed Operator menu, open the NVIDIA GPU Operator settings, get to the ClusterPolicy tab, and edit the ClusterPolicy.</p>
<p><img alt="Cluster Policy" src="../img/cluster-policy.png" /></p>
</li>
<li>
<p>Edit the YAML, and add the toleration in the daemonset section:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia.com/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-cluster-policy</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">vgpuDeviceManager</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">migManager</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">dcgm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">gfd</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">dcgmExporter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">cdi</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">driver</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">devicePlugin</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">mig</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">sandboxDevicePlugin</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">validator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">nodeStatusExporter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">daemonsets</span><span class="p">:</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">tolerations</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">effect</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">NoSchedule</span>
<span class="w">        </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">restrictedaccess</span>
<span class="w">        </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Exists</span>
<span class="w">  </span><span class="nt">sandboxWorkloads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">gds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">vgpuManager</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">vfioManager</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="nt">toolkit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="nn">...</span>
</code></pre></div>
</li>
</ul>
</li>
</ul>
<p>That's it, the operator is now able to deploy all the NVIDIA tooling on the nodes, even if they have the <code>restrictedaccess</code> taint. Repeat the procedure for any other taint you want to apply to your nodes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The first taint that you want to apply on GPU nodes is <code>nvidia.com/gpu</code>. This is the standard taint for which the NVIDIA Operator has a built-in toleration, so no need to add it. Likewise, Notebooks, Workbenches or other components from ODH/RHOAI that request GPUs will already have this toleration in place. For other Pods you schedule yourself, or using Pipelines, you should make sure the toleration is also applied. Doing this will ensure that only Pods really requiring GPUs are scheduled on those nodes.</p>
<p>You can of course apply many different taints at the same time. You would simply have to apply the matching toleration on the NVIDIA GPU Operator, as well as on the Pods that need to run there.</p>
</div>
<h3 id="autoscaler-and-gpus">Autoscaler and GPUs</h3>
<p>As they are expensive, GPUs are good candidates to put behind an Autoscaler. But due <a href="https://access.redhat.com/solutions/6055181" target="_blank">to this</a> there are some subtleties if you want everything to go smoothly.</p>
<h4 id="configuration">Configuration</h4>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For the autoscaler to work properly with GPUs, you have to set a specific label to the MachineSet. It will help to Autoscaler figure out (in fact simulate) what it is allowed to do. This is especially true if you have different MachineSets that feature different types of GPUs.</p>
<p>As per the referenced article above, the <code>type</code> for gpus you set through the label cannot be <code>nvidia.com/gpu</code> (as you will sometimes find in the standard documentation), because it's not a valid label. Therefore, only for the autoscaling purpose, you should give the <code>type</code> a specific name with letters, numbers and dashes only, like <code>Tesla-T4-SHARED</code> in this example.</p>
</div>
<ul>
<li>
<p>Edit the MachineSet configuration to add the label that the Autoscaler will expect:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nn">...</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">template</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">spec</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">metadata</span><span class="p">:</span>
<span class="w">        </span><span class="nt">labels</span><span class="p">:</span>
<span class="w">          </span><span class="nt">cluster-api/accelerator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Tesla-T4-SHARED</span>
</code></pre></div>
</li>
<li>
<p>Create your ClusterAutoscaler configuration (example):</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">autoscaling.openshift.io/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterAutoscaler</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;default&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">logVerbosity</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">  </span><span class="nt">maxNodeProvisionTime</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">15m</span>
<span class="w">  </span><span class="nt">podPriorityThreshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-10</span>
<span class="w">  </span><span class="nt">resourceLimits</span><span class="p">:</span>
<span class="w">    </span><span class="nt">gpus</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Tesla-T4-SHARED</span>
<span class="w">        </span><span class="nt">min</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">        </span><span class="nt">max</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">scaleDown</span><span class="p">:</span>
<span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">delayAfterAdd</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20m</span>
<span class="w">    </span><span class="nt">delayAfterDelete</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5m</span>
<span class="w">    </span><span class="nt">delayAfterFailure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30s</span>
<span class="w">    </span><span class="nt">unneededTime</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5m</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code>delayAfterAdd</code> parameter has to be set higher than standard value as NVIDIA tooling can take a lot of time to deploy, 10-15mn.</p>
</div>
</li>
<li>
<p>Create the MachineSet Autoscaler:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">autoscaling.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineAutoscaler</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machineset-name</span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;openshift-machine-api&quot;</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span>
<span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machineset-name</span>
</code></pre></div>
</li>
</ul>
<h4 id="scaling-to-zero">Scaling to zero</h4>
<p>As GPUs are expensive resources, you may want to <strong>scale down your MachineSet to zero to save on resources</strong>. This will however require some more configuration than just setting the minimum size to zero...</p>
<p>First, some background to help you understand and enable you to solve issues that may arise. You can skip the whole explanation, but it's worth it, so please bear with me.</p>
<p>When you request resources that aren't available, the Autoscaler looks at all the MachineAutoscalers that are available, with their corresponding MachineSets. But how to know which one to use? Well, it will first simulate the provisioning of a Node from each MachineSet, and see if it would fit the request. Of course, if there is already at least one Node available from a given MachineSet, the simulation would be bypassed as the Autoscaler already knows what it will get. If there are different MachineSets that fit and to choose from, the default and only "Expander" available for now in OpenShift to make its decision is <code>random</code>. So it will simply picks one totally randomly.</p>
<p>That's all perfect and everything, but for GPUs, if you don't start the Node for real, we don't know what's in it! So that's where we have to help the Autoscaler with a small hint.</p>
<ul>
<li>
<p>Set this annotation manually if it's not there. It will stick after the first scale up though, along with some other annotations the Autoscaler will add, thanks for its newly discovered knowledge.</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">annotations</span><span class="p">:</span>
<span class="w">    </span><span class="nt">machine.openshift.io/GPU</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1&quot;</span>
</code></pre></div>
</li>
</ul>
<p>Now to the other issue that may happen if you are in an environment with multiple Availability Zones (AZ)...</p>
<p>Although when you define a MachineSet you can set the AZ and have all the Nodes spawned properly in it, the Autoscaler simulator is not that clever. So it will simply pick a Zone at random. If this is not the one where you want/need your Pod to run, this will be a problem...</p>
<p>For example, you may already have a Persistent Volume (PV) attached to you Notebook. If your storage does now support AZ-spanning (like AWS EBS volumes), your PV is bound to a specific AZ. If the Simulator creates a virtual Node in a different AZ, there will be a mismatch, your Pod would not be schedulable on this Node, and the Autoscaler will (wrongly) conclude that it cannot use this MachineSet for a scale up!</p>
<p>Here again, we have to give a hint to the Autoscaler to what the Node will look like in the end.</p>
<ul>
<li>
<p>In you MachineSet, in the labels that will be added to the node, add information regarding the topology of the Node, as well as for the volumes that may be attached to it. For example:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">template</span><span class="p">:</span>
<span class="w">    </span><span class="nt">spec</span><span class="p">:</span>
<span class="w">      </span><span class="nt">metadata</span><span class="p">:</span>
<span class="w">        </span><span class="nt">labels</span><span class="p">:</span>
<span class="w">          </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">          </span><span class="l l-Scalar l-Scalar-Plain">topology.kubernetes.io/zone</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">us-east-2a</span>
<span class="w">          </span><span class="nt">topology.ebs.csi.aws.com/zone</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">us-east-2a</span>
</code></pre></div>
</li>
</ul>
<p>With this, the simulated Node will be at the right place, and the Autoscaler will consider the MachineSet valid for scale up!</p>
<p>Reference material:</p>
<ul>
<li><a href="https://cloud.redhat.com/blog/autoscaling-nvidia-gpus-on-red-hat-openshift">https://cloud.redhat.com/blog/autoscaling-nvidia-gpus-on-red-hat-openshift</a></li>
<li><a href="https://access.redhat.com/solutions/6055181">https://access.redhat.com/solutions/6055181</a></li>
<li><a href="https://bugzilla.redhat.com/show_bug.cgi?id=1943194">https://bugzilla.redhat.com/show_bug.cgi?id=1943194</a></li>
</ul>
<h3 id="gpu-partitioning-sharing">GPU Partitioning / Sharing</h3>
<p>There are also situations where the GPU(s) you have access to might be oversized for the task at hand, and having a single user or process lock-up and "hog" that GPU can be inefficient. 
There are thankfully some partitioning strategies that can be brought to bear in order to deal with these situations. 
Although there are multiple techniques, with <a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide?tab=readme-ov-file#14-pros-and-cons-of-gpu-sharing-methods">various pros and cons</a>, the net effect of these implementations is that what used to look like a single GPU will then look like multiple GPUs. 
Obviously, there is no magic in the process, and the laws of physics still hold: there are trade-offs, and the multiple "partitioned" GPUs are not going to be faster or crunch more data than the real underlying physical GPU.  </p>
<p>If this is a situation that you are facing, consult this <a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide">repository</a> for more detailed information and examples.</p>
<h4 id="time-slicing-gpu-sharing">Time Slicing (GPU sharing)</h4>
<p>Do you want to <strong>share GPUs</strong> between different Pods? Time Slicing is one of the solutions you can use!</p>
<p>The NVIDIA GPU Operator enables oversubscription of GPUs through a set of extended options for the NVIDIA Kubernetes Device Plugin. GPU time-slicing enables workloads that are scheduled on oversubscribed GPUs to interleave with one another.</p>
<p>This mechanism for enabling time-slicing of GPUs in Kubernetes enables a system administrator to define a set of replicas for a GPU, each of which can be handed out independently to a pod to run workloads on. Unlike Multi-Instance GPU (MIG), there is no memory or fault-isolation between replicas, but for some workloads this is better than not being able to share at all. Internally, GPU time-slicing is used to multiplex workloads from replicas of the same underlying GPU.</p>
<ul>
<li><em><a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html">Time Slicing Full reference</a></em></li>
<li><em><a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide?tab=readme-ov-file#31-time-slicing">Time Slicing Example Repository</a></em></li>
</ul>
<h5 id="configuration_1">Configuration</h5>
<p>This is a simple example on how to quickly setup Time Slicing on your OpenShift cluster. In this example, we have a MachineSet that can provide nodes with one T4 card each that we want to make "seen" as 4 different cards so that multiple Pods requiring GPUs can be launched, even if we only have one node of this type.</p>
<ul>
<li>
<p>Create the ConfigMap that will define how we want to slice our GPU:</p>
<div class="highlight"><pre><span></span><code><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">time-slicing-config</span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span>
<span class="nt">data</span><span class="p">:</span>
<span class="w">  </span><span class="nt">tesla-t4</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|-</span>
<span class="w">    </span><span class="no">version: v1</span>
<span class="w">    </span><span class="no">sharing:</span>
<span class="w">      </span><span class="no">timeSlicing:</span>
<span class="w">        </span><span class="no">resources:</span>
<span class="w">        </span><span class="no">- name: nvidia.com/gpu</span>
<span class="w">          </span><span class="no">replicas: 4</span>
</code></pre></div>
<blockquote>
<p>NOTE
    - The ConfigMap has to be called <code>time-slicing-config</code> and must be created in the <code>nvidia-gpu-operator</code> namespace.
    - You can add many different resources with different configurations. You simply have to provide the corresponding Node label that has been applied by the operator, for example <code>name: nvidia.com/mig-1g.5gb / replicas: 2</code> if you have a MIG configuration applied to a Node with a A100.
    - You can modify the value of <code>replicas</code> to present less/more GPUs. Be warned though: all the Pods on this node will share the GPU memory, with no reservation. The more slices you create, the more risks of OOM errors (out of memory) you get if your Pods are hungry (or even only one!).</p>
</blockquote>
</li>
<li>
<p>Modify the ClusterPolicy called <code>gpu-cluster-policy</code> (accessible from the NVIDIA Operator view in the <code>nvidia-gpu-operator</code> namespace) to point to this configuration, and eventually add the default configuration (in case you nodes are not labelled correctly, see below)</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia.com/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-cluster-policy</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">devicePlugin</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">config</span><span class="p">:</span>
<span class="w">      </span><span class="nt">default</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tesla-t4</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">time-slicing-config</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</code></pre></div>
</li>
<li>
<p>Apply label to your MachineSet for the specific slicing configuration you want to use on it:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">template</span><span class="p">:</span>
<span class="w">    </span><span class="nt">spec</span><span class="p">:</span>
<span class="w">      </span><span class="nt">metadata</span><span class="p">:</span>
<span class="w">        </span><span class="nt">labels</span><span class="p">:</span>
<span class="w">          </span><span class="nt">nvidia.com/device-plugin.config</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tesla-t4</span>
</code></pre></div>
</li>
</ul>
<h4 id="multi-instance-gpu-mig">Multi-Instance GPU (MIG)</h4>
<p><a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">Multi-Instance GPU (MIG)</a> enables a single physical GPU to be partitioned into several isolated instances, each with its own compute resources, memory, and performance profiles.</p>
<p>There are two types of MIG strategies: <code>Single</code> and <code>Mixed</code>. The single MIG strategy should be utilized when all GPUs on a node have MIG enabled, while the <code>Mixed</code> MIG strategy should be utilized when not all GPUs on a node have MIG enabled.</p>
<blockquote>
<p>NOTE: MIG is only supported with the following NVIDIA GPU Types - A30, A100, A100X, A800, AX800, H100, H200, and H800.</p>
</blockquote>
<ul>
<li><em><a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-mig.html">MIG Full reference</a></em></li>
<li><em><a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide/blob/main/gpu-sharing-instance/instance/components/mig-single/README.md">MIG Single Example Repository</a></em></li>
<li><em><a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide/blob/main/gpu-sharing-instance/instance/components/mig-mixed/README.md">MIG Mixed Example Repository</a></em></li>
</ul>
<h4 id="multi-process-service-mps">Multi-Process Service (MPS)</h4>
<p>Multi-Process Service (MPS) facilitates concurrent sharing of a single GPU among multiple CUDA applications.</p>
<p>MPS is an alternative, binary-compatible implementation of the CUDA Application Programming Interface (API). The MPS runtime architecture is designed to transparently enable co-operative multi-process CUDA applications.</p>
<ul>
<li><em><a href="https://docs.nvidia.com/deploy/mps/index.html">MPS Full reference</a></em></li>
<li><em><a href="https://github.com/rh-aiservices-bu/gpu-partitioning-guide/blob/main/gpu-sharing-instance/instance/components/mps/README.md">MPS Example Repository</a></em></li>
</ul>
<blockquote>
<p>NOTE: Despite the tests passing, MPS isn't working correctly on OpenShift currently, due to only one process per GPU can run at any time. RH and NVIDIA engineers are working to fix this issue as soon as possible.</p>
</blockquote>
<h3 id="aggregating-gpus-multi-gpu">Aggregating GPUs (Multi-GPU)</h3>
<p>Some Large Language Models (LLMs), such as Llama-3-70B and <a href="https://huggingface.co/blog/falcon-180b#hardware-requirements">Falcon 180B</a>, can be too large to fit into the memory of a single GPU (vRAM). Or in some cases, GPUs that would be large-enough might be difficult to obtain.  If you find yourself in such a situation, it is natural to wonder whether an aggregation of multiple, smaller GPUs can be used instead of one single large GPU.</p>
<p>Thankfully, the answer is essentially Yes. To address these challenges, we can use more advanced configurations to distribute the LLM workload across several GPUs. One option is leveraging <a href="https://huggingface.co/docs/transformers/perf_train_gpu_many#tensor-parallelism">tensor parallelism</a>, where the LLM is split across several GPUs, with each GPU processing a portion of the model's tensors. This approach ensures efficient utilization of available resources (GPUs) across one or several workers.</p>
<p>Some Serving Runtimes, such as vLLM, support tensor parallelism, allowing for both single-worker and multi-worker configurations (the difference whether your GPUs are all in the same machine, or are spread across machines). </p>
<p>vLLM has been added as an Out-of-the-box serving runtime, starting with Red Hat OpenShift AI version 2.10 link to our <a href="https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.10/html-single/serving_models">RHOAI doc</a></p>
<p>For a detailed guide on implementing these solutions, refer to <a href="https://github.com/rh-aiservices-bu/multi-gpu-llms">our repository</a>.</p>
<ul>
<li><em><a href="https://github.com/rh-aiservices-bu/multi-gpu-llms?tab=readme-ov-file#71-single-node---multiple-gpu-demos">Single Worker Node - Multiple GPUs Example Repository</a></em></li>
<li><em><a href="https://github.com/rh-aiservices-bu/multi-gpu-llms?tab=readme-ov-file#72-multi-node---multiple-gpu-demos">Multiple Worker Node - Multiple GPUs Example Repository</a></em></li>
</ul>
<h3 id="nvidia-vgpus">NVIDIA vGPUs</h3>
<p>NVIDIA vGPU is a software that allows virtualisation of a whole GPU, such that it can be assigned to multiple VMs, within VMWare vSphere. In terms of OpenShift, this means that a single physical GPU could be split such that it can be assigned to several clusters.</p>
<h4 id="pros">Pros</h4>
<ul>
<li>
<p>Helpful in particularly resource constrainted environments where GPUs need to be spread out.</p>
</li>
<li>
<p>Useful for redistributing GPU compute to other clusters, when a full GPU would remain underutilised.</p>
</li>
<li>
<p>Physical GPUs can be split in vSphere via either timeslicing, or MIG, if available for the model of GPU.</p>
</li>
</ul>
<h4 id="cons">Cons</h4>
<ul>
<li>
<p>NVIDIA vGPU is a licensed product, therefore a license per vGPU-equipped OCP worker node is required. Communication between the vGPU-equipped worker and a license service will also be required.</p>
</li>
<li>
<p>NVIDIA vGPUs require a vGPU specific driver image, which need to be either built manually, or retrieved from the <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC Catalog</a>. Both of these require an active NVIDIA AI Enterprise subscription.</p>
</li>
<li>
<p>Additional setup of the vSphere ESXi hosts is required.</p>
</li>
<li>
<p>Workers with vGPUs have a single allocatable <code>nvidia.com/gpu</code> resource, which cannot be split any further.</p>
</li>
</ul>
<h4 id="setup">Setup</h4>
<p>Setting up vGPUs to be used on OpenShift requires some pre-work on the ESXi hosts themselves, that can be found in <a href="https://docs.nvidia.com/vgpu/deployment/vmware/latest/manager.html#">NVIDIA documentation</a>. </p>
<p>Post ESXi setup, equipping OpenShift worker nodes with vGPUs isn't directly possible with the vSphere OpenShift installer. To get around this, you'll need to create a custom RHCOS template within vSphere that is preconfigured with the vGPU PCI device. The <a href="https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/machine_management/managing-compute-machines-with-the-machine-api#machineset-yaml-vsphere_creating-machineset-vsphere">RHCOS template can be referenced</a> in the <code>machineSet</code> definition as shown below.</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">machine.openshift.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MachineSet</span>
<span class="nn">...</span>
<span class="nt">template</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">spec</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">providerSpec</span><span class="p">:</span>
<span class="w">      </span><span class="nt">value</span><span class="p">:</span>
<span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">template</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;vm_template_name&gt;</span>
</code></pre></div>
<blockquote>
<p>NOTE: You will need a separate <code>machineSet</code> and RHCOS template, for each vGPU configuration you need. For instance, if you're using a MIG sliced A100 80GB for your vGPUs, you
may want a <code>machineSet</code> each for <code>1g.10gb</code> slices, <code>3g.40gb</code> slices and <code>7g.80gb</code> slices. </p>
</blockquote>
<p>Once the worker node has been provisioned, and the Node Feature Discovery (NFD) and NVIDIA GPU operator pods have spun up on it, the worker node should have a single allocatable <code>nvidia.com/gpu</code> resource. Unfortunately, vGPUs can't be partitioned any smaller in OpenShift, using any of the above methods (i.e. Timeslicing, MPS, MIG) therefore, a single vGPU can be allocated to only a single workload at a time.</p>
<h4 id="vgpu-drivers">vGPU Drivers</h4>
<p>As mentioned in the pros and cons list, vGPUs require specific drivers to work. These drivers can be either built according to NVIDIA's <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/install-gpu-operator-vgpu.html#build-the-driver-container">documentation</a>, or they can be retrieved directly from the <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC catalog</a>. </p>
<p>The version of the NVIDIA vGPU driver, needs to correspond to the version of the vGPU Manager image, that is on the underlying ESXi host. For instance, if <a href="https://docs.nvidia.com/vgpu/17.0/grid-vgpu-release-notes-vmware-vsphere/index.html#vgpu-software-driver-versions">vGPU software version 17.6</a> was being used, the vGPU Manager version would be <code>550.163.02</code>, and the corresponding maximum version for the vGPU Driver would be <code>550.163.01</code>.</p>
<p>If the drivers are to be built, or utilised in a disconnected OCP environment, then a private image registry is required to push the images to. In the case that driver images are pulled directly from NVIDIA NGC, an image pull secret needs to <a href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/nvaie-with-ocp.html#create-the-ngc-secret">be created that contains the NGC API Key</a>.</p>
<p>To pull a specific vGPU driver image, it needs to be defined in the <code>clusterPolicy</code> CR. Below is an example that pulls directly from NVIDIA NGC.</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia.com/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-cluster-policy</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">driver</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="nt">repository</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvcr.io/nvidia/vgpu</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">vgpu-guest-driver-X</span>
<span class="w">    </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">550.163.01-rhcos4.XX</span>
<span class="w">    </span><span class="nt">imagePullSecrets</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ngc-secret</span>
</code></pre></div>
<h4 id="licensing">Licensing</h4>
<p>Licensing of the vGPUs is done through the NVIDIA License Portal (NLP). NVIDIA offers a solution for both connected and disconnected environments, that's their Cloud License Service (<a href="https://docs.nvidia.com/license-system/latest/nvidia-license-system-user-guide/index.html#about-cls-instances">CLS</a>) and Delegated License Service (<a href="https://docs.nvidia.com/license-system/latest/nvidia-license-system-user-guide/index.html#about-dls-instances">DLS</a>) respectively. All communication between either license services, and the vGPU-equipped worker nodes, is through HTTPS / TLS port 443.</p>
<p>An NVIDIA CLS instance is hosted directly on the NLP. This means that NVIDIA maintains the CLS instance themselves, and so, the lifecycle of the CLS doesn't need to be managed directly. Comparatively, an NVIDIA DLS instance is deployed on-premises, either directly on the OpenShift cluster, or on a VM. This means that the DLS instance will need to be deployed and maintained directly, which includes downloading licenses from the NLP and manually uploading them to the instance.</p>
<p>Irrespective of which license service has been chosen, a client configuration token will be able to be generated. The client configuration token contains information about which service instance generated it, and is used by the NVIDIA GPU operator to lease licenses for the vGPU-equipped workers. To do this, you need to create the following <code>configMap</code></p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>
<span class="nt">metaData</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">licensing-config</span>
<span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia-gpu-operator</span>
<span class="nt">data</span><span class="p">:</span>
<span class="w">  </span><span class="nt">client_configuration_token.tok</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;TOKEN&gt;</span>
<span class="w">  </span><span class="nt">gridd.conf</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no"># Description: Set Feature to be enabled</span>
<span class="w">    </span><span class="no"># Data type: integer</span>
<span class="w">    </span><span class="no"># Possible values:</span>
<span class="w">    </span><span class="no"># 0 =&gt; for unlicensed state</span>
<span class="w">    </span><span class="no"># 1 =&gt; for NVIDIA vGPU</span>
<span class="w">    </span><span class="no"># 2 =&gt; for NVIDIA RTX Virtual Workstation</span>
<span class="w">    </span><span class="no"># 4 =&gt; for NVIDIA Virtual Compute Server</span>
<span class="w">    </span><span class="no">FeatureType=1</span>
<span class="w">    </span><span class="no"># ProxyServerAddress=&lt;ADDRESS&gt; # Required if you have a proxy between OCP and CLS.</span>
<span class="w">    </span><span class="no"># ProxyServerPort=&lt;PORT&gt;</span>
</code></pre></div>
<p>This <code>configMap</code> can then be referenced in the NVIDIA GPU operator <code>clusterPolicy</code> CR, as shown below:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nvidia.com/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterPolicy</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpu-cluster-policy</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">driver</span><span class="p p-Indicator">:</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">licensingConfig</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">nlsEnabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">configMapName</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;licensing-config&quot;</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</code></pre></div>
<p>To validate that the vGPU worker nodes are licensed, NVIDIA Data Centre GPU Manager (DCGM) will export the <code>DCGM_FI_DEV_VGPU_LICENSE_STATUS</code> metric, per worker node. This will show a value of <code>1</code> if the worker node is licensed properly. Alternatively, the license service instance should show that the license(s) are allocated.</p>
<h4 id="references">References</h4>
<ul>
<li>
<p><a href="https://docs.nvidia.com/vgpu/deployment/vmware/latest/index.html">NVIDIA vGPU: VMware Deployment Guide</a></p>
</li>
<li>
<p><a href="https://docs.nvidia.com/license-system/latest/nvidia-license-system-user-guide/index.html">NVIDIA License System User Guide</a></p>
</li>
<li>
<p><a href="https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/nvaie-with-ocp.html#openshift-container-platform-on-vmware-vsphere-with-nvidia-vgpus">NVIDIA OpenShift Container Platform on VMware vSphere with NVIDIA vGPUs</a></p>
</li>
</ul>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
<footer class="md-footer">
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                
                powered by
                <a href="https://www.mkdocs.org" title="MkDocs" target="_blank">MkDocs</a>
                and
                <a href="https://squidfunk.github.io/mkdocs-material/"
                   title="Material for MkDocs" target="_blank">
                    Material for MkDocs</a>
            </div>
            
            <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://discord.gg/q2Y6THPQKb" target="_blank" rel="noopener" title="discord.gg" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.reddit.com/r/AI_on_OpenShift/" target="_blank" rel="noopener" title="www.reddit.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://odh-io.slack.com/" target="_blank" rel="noopener" title="odh-io.slack.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1s21.16-47.06 47.06-47.06h47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06S448 171 448 196.9s-21.16 47.06-47.06 47.06h-47.06zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06S309 480 283.1 480s-47.06-21.16-47.06-47.06v-47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06s21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06z"/></svg>
    </a>
  
</div>
            
        </div>
    </div>
</footer>

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            

  
    
  


  
    
  



  


<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="analytics" checked>
          <span class="task-list-indicator"></span>
          Google Analytics
        </label>
      </li>
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        </label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.instant", "navigation.tracking", "navigation.sections", "navigation.indexes", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.expand"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.60a45f97.min.js"></script>
      
    
  </body>
</html>